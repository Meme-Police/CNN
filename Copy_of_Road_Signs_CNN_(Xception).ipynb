{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Road Signs CNN (Xception).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqDPGHIh7TR_",
        "outputId": "d246a3fe-0404-4bf0-c374-186f585b9fe7"
      },
      "source": [
        "# Note: After you run this cell, the training and test data will be available in\r\n",
        "# the file browser. (Click the folder icon on the left to view it)\r\n",
        "#\r\n",
        "# If you don't see the data after the cell completes, click the refresh button\r\n",
        "# in the file browser (folder icon with circular arrow)\r\n",
        "\r\n",
        "# First, let's download and unzip the data\r\n",
        "!echo \"Downloading files...\"\r\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training1.zip\r\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/training2.zip\r\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test.zip\r\n",
        "!wget -q https://github.com/byui-cse/cse450-course/raw/master/data/roadsigns/test_classes.csv\r\n",
        "\r\n",
        "!echo \"Unzipping files...\"\r\n",
        "!unzip -q /content/training1.zip\r\n",
        "!unzip -q /content/training2.zip\r\n",
        "!unzip -q /content/test.zip\r\n",
        "\r\n",
        "# Combine the two traning directories\r\n",
        "!echo \"Mergining training data...\"\r\n",
        "!mkdir /content/training\r\n",
        "!mv /content/training1/* /content/training\r\n",
        "!mv /content/training2/* /content/training\r\n",
        "\r\n",
        "# Cleanup\r\n",
        "!echo \"Cleaning up...\"\r\n",
        "!rmdir /content/training1\r\n",
        "!rmdir /content/training2\r\n",
        "!rm training1.zip\r\n",
        "!rm training2.zip\r\n",
        "!rm test.zip\r\n",
        "\r\n",
        "!echo \"Data ready.\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading files...\n",
            "Unzipping files...\n",
            "Mergining training data...\n",
            "Cleaning up...\n",
            "Data ready.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxZPFPvs7bW3"
      },
      "source": [
        "# Import libraries\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "from tensorflow.keras import layers\r\n",
        "from tensorflow.keras.preprocessing import image_dataset_from_directory\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "from PIL import Image\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5L-b2pld7dqB",
        "outputId": "54313257-96e5-4770-d5da-0be925ec47b2"
      },
      "source": [
        "# Create an image training dataset\r\n",
        "\r\n",
        "# We're using keras' image_dataset_from_directory method to load our image data.\r\n",
        "# See (https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image_dataset_from_directory) for details\r\n",
        "#\r\n",
        "# A couple of things to note:\r\n",
        "# 1. We're specifying a number for the seed, so we'll always get the same shuffle and split of our images.\r\n",
        "# 2. Class names are inferred automatically from the image subdirectory names.\r\n",
        "# 3. We're splitting the training data into 80% training, 20% validation. \r\n",
        "\r\n",
        "training_dir = '/content/training/'\r\n",
        "image_size = (100, 100)\r\n",
        "\r\n",
        "# Split up the training data images into training and validations sets\r\n",
        "training_data = image_dataset_from_directory(training_dir, validation_split=.2, subset='training', seed=42, image_size=image_size)\r\n",
        "validation_data = image_dataset_from_directory(training_dir, validation_split=.2, subset='validation', seed=42, image_size=image_size)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 39209 files belonging to 43 classes.\n",
            "Using 31368 files for training.\n",
            "Found 39209 files belonging to 43 classes.\n",
            "Using 7841 files for validation.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5nUng1fIaUlJ"
      },
      "source": [
        "df = pd.read_csv(str(\"/content/test_classes.csv\"))\r\n",
        "test_data = np.array([np.array(Image.open(\"/content/test/\" + fname)) for fname in df[\"Filename\"]])\r\n",
        "test_labels = df[\"ClassId\"]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lfAFq-8YHucb"
      },
      "source": [
        "# test_labels.dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJZyMsO47feL"
      },
      "source": [
        "# # View first 9 images and their class labels\r\n",
        "# plt.figure(figsize=(10, 10))\r\n",
        "# for images, labels in training_data.take(1):\r\n",
        "#   for i in range(9):\r\n",
        "#     ax = plt.subplot(3, 3, i + 1)\r\n",
        "#     plt.imshow(images[i].numpy().astype(\"uint8\"))\r\n",
        "#     plt.title(training_data.class_names[labels[i]])\r\n",
        "#     plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgZyHRkgBo_I"
      },
      "source": [
        "imported_model = keras.applications.Xception(weights=None, input_shape=(100, 100, 3), include_top=False)\r\n",
        "\r\n",
        "model = tf.keras.Sequential([\r\n",
        "  keras.Input(shape=(100, 100, 3)),\r\n",
        "  layers.experimental.preprocessing.Rescaling(1./255),\r\n",
        "  layers.experimental.preprocessing.RandomTranslation(0.20, 0.20),\r\n",
        "  layers.experimental.preprocessing.RandomZoom(0.20, 0.20),\r\n",
        "  layers.experimental.preprocessing.RandomRotation(0.07),\r\n",
        "  layers.experimental.preprocessing.RandomContrast(0.25),\r\n",
        "\r\n",
        "  imported_model,\r\n",
        "\r\n",
        "  layers.GlobalAveragePooling2D(),\r\n",
        "  layers.Dense(43)\r\n",
        "])\r\n",
        "\r\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\r\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\r\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESS255mNtVHb",
        "outputId": "2d645882-c05d-4034-bed3-98e30469e4af"
      },
      "source": [
        "model.fit(training_data, epochs=7, validation_data=validation_data)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/7\n",
            "981/981 [==============================] - 173s 138ms/step - loss: 3.9310 - accuracy: 0.0839 - val_loss: 11.4594 - val_accuracy: 0.0661\n",
            "Epoch 2/7\n",
            "981/981 [==============================] - 134s 137ms/step - loss: 2.6150 - accuracy: 0.2215 - val_loss: 2.6000 - val_accuracy: 0.3521\n",
            "Epoch 3/7\n",
            "981/981 [==============================] - 134s 136ms/step - loss: 1.4938 - accuracy: 0.4942 - val_loss: 1.3392 - val_accuracy: 0.6293\n",
            "Epoch 4/7\n",
            "981/981 [==============================] - 134s 136ms/step - loss: 0.6022 - accuracy: 0.7996 - val_loss: 0.3060 - val_accuracy: 0.8981\n",
            "Epoch 5/7\n",
            "981/981 [==============================] - 134s 136ms/step - loss: 0.2497 - accuracy: 0.9190 - val_loss: 0.1778 - val_accuracy: 0.9393\n",
            "Epoch 6/7\n",
            "981/981 [==============================] - 133s 136ms/step - loss: 0.1595 - accuracy: 0.9485 - val_loss: 0.0654 - val_accuracy: 0.9786\n",
            "Epoch 7/7\n",
            "981/981 [==============================] - 133s 136ms/step - loss: 0.1205 - accuracy: 0.9622 - val_loss: 0.0797 - val_accuracy: 0.9756\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb207ea5e50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAFMqZ9fGkOt",
        "outputId": "a44a1b02-83bd-41e3-8366-8aa9571f5977"
      },
      "source": [
        "\r\n",
        "\r\n",
        "print(\"Test Results:\")\r\n",
        "test_loss, test_acc = model.evaluate(test_data, test_labels.astype(\"uint8\"), verbose=2)\r\n",
        "y = model.predict(test_data)\r\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Results:\n",
            "395/395 - 11s - loss: 0.2745 - accuracy: 0.9338\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q34MMdLVDYP8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_7BT_YMF9Dp"
      },
      "source": [
        "def findF1(cm):\r\n",
        "  tp = 0\r\n",
        "  fp = 0\r\n",
        "  fn = 0\r\n",
        "  for i in range(43):\r\n",
        "    for j in range(43):  \r\n",
        "      if (i == j):\r\n",
        "        tp += cm[i][j]\r\n",
        "      else:\r\n",
        "        fp += cm[j][i] \r\n",
        "        fn += cm[i][j]\r\n",
        "  tp = tp / 12630\r\n",
        "  fp = fp / 12630\r\n",
        "  fn = fn / 12630\r\n",
        "  precision = tp / (tp + fp)\r\n",
        "  recall = tp / (tp + fn)\r\n",
        "  return 2 * ((precision * recall) / (precision + recall))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1olhIZZVI9qA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OP2jCvGnpX2X",
        "outputId": "432f8d47-62fe-4b9e-c706-02a0b9cd7360"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\r\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\r\n",
        "listAcc = list()\r\n",
        "y_true = test_labels.to_list()\r\n",
        "y_pred = np.argmax(y, axis=1)\r\n",
        "cm = confusion_matrix(y_true, y_pred)\r\n",
        "for i in range(43):\r\n",
        "  total = 0\r\n",
        "  right = 0\r\n",
        "  for j in range(43):\r\n",
        "    if (i == j):\r\n",
        "      right += cm[i][j]\r\n",
        "    total += cm[i][j]\r\n",
        "  listAcc.append((right / total))\r\n",
        "exact = 0\r\n",
        "for x in range(43):\r\n",
        "  if listAcc[x] > .95:\r\n",
        "    exact += 1\r\n",
        "print(exact)\r\n",
        "print(cm)\r\n",
        "print(y.shape)\r\n",
        "print(listAcc)\r\n",
        "print(findF1(cm))\r\n",
        "np.savetxt(\"foo.csv\", cm, delimiter=',', fmt = \"%i\")\r\n"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n",
            "[[ 40   0   0 ...   0   0   0]\n",
            " [  0 688   0 ...   0   0   0]\n",
            " [  0   1 681 ...   5   0   0]\n",
            " ...\n",
            " [  0   0   0 ...  83   0   0]\n",
            " [  0   0   0 ...   0  59   0]\n",
            " [  0   0   0 ...   0   0  89]]\n",
            "(12630, 43)\n",
            "[0.6666666666666666, 0.9555555555555556, 0.908, 0.9155555555555556, 0.8545454545454545, 0.9904761904761905, 0.52, 0.9266666666666666, 0.9888888888888889, 0.9979166666666667, 0.9984848484848485, 0.9380952380952381, 0.8681159420289855, 0.9958333333333333, 1.0, 0.9952380952380953, 1.0, 0.9666666666666667, 0.9384615384615385, 0.9333333333333333, 0.9888888888888889, 0.6, 0.9416666666666667, 0.8733333333333333, 0.7666666666666667, 0.9729166666666667, 0.9277777777777778, 0.4, 0.74, 1.0, 0.78, 0.9481481481481482, 0.7333333333333333, 0.9761904761904762, 0.9833333333333333, 0.9564102564102565, 0.8833333333333333, 0.9833333333333333, 0.9956521739130435, 0.9666666666666667, 0.9222222222222223, 0.9833333333333333, 0.9888888888888889]\n",
            "0.9338083927157561\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_t3eNgOM5jbd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}